{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dialog Act Classification using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using the Switchboard Dialog Act Corpus for training.\n",
    "##### Corpus can be downloaded from http://compprag.christopherpotts.net/swda.html. \n",
    "##### The downloaded dataset should be kept in a data folder in the same directory as this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = glob.glob(\"data/sw*/sw*.csv\")\n",
    "frames = []\n",
    "for i in range(0, len(f)):\n",
    "    frames.append(pd.read_csv(f[i]))\n",
    "result = pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For the purpose of training using only part of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of converations in the dataset: 51739\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of converations in the dataset:\",len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The dataset has many features, we are only using act_tag and text for this training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = result[['act_tag','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_tag</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o</td>\n",
       "      <td>Okay.  /</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qw</td>\n",
       "      <td>{D So, }</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qy^d</td>\n",
       "      <td>[ [ I guess, +</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+</td>\n",
       "      <td>What kind of experience [ do you, + do you ] h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+</td>\n",
       "      <td>I think, ] + {F uh, } I wonder ] if that worke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  act_tag                                               text\n",
       "0       o                                           Okay.  /\n",
       "1      qw                                           {D So, }\n",
       "2    qy^d                                     [ [ I guess, +\n",
       "3       +  What kind of experience [ do you, + do you ] h...\n",
       "4       +  I think, ] + {F uh, } I wonder ] if that worke..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifying Yes-No-Question('qy'), Statement-non-opinion('sd'), Statement-opinion('sv') dialogues.\n",
    "##### Tags information can be found here http://compprag.christopherpotts.net/swda.html#tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_of_tags = {\n",
    "    'qy':'Yes-No-Question',\n",
    "    'sd':'Statement-non-opinion',\n",
    "    'sv':'Statement-opinion'\n",
    "}\n",
    "frames = []\n",
    "for e in ['qy', 'sd', 'sv']:\n",
    "    frames.append(reduced_df.loc[reduced_df['act_tag'] == e])\n",
    "reduced_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### check frequency of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sd    17713\n",
       "sv     5375\n",
       "qy      887\n",
       "Name: act_tag, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df['act_tag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced_df['act_tag'].ipynb_checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique tags\n",
    "unique_tags = set()\n",
    "for tag in reduced_df['act_tag']:\n",
    "    unique_tags.add(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding_dic = pd.get_dummies(list(unique_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_encoding = []\n",
    "for i in range(0, len(reduced_df)):\n",
    "    tags_encoding.append(one_hot_encoding_dic[reduced_df['act_tag'].iloc[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for i in range(0, len(reduced_df)):\n",
    "    sentences.append(reduced_df['text'].iloc[i].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvectors = {}\n",
    "index = 1\n",
    "for s in sentences:\n",
    "    for w in s:\n",
    "        if w not in wordvectors:\n",
    "            wordvectors[w] = index\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = len(max(sentences, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = []\n",
    "for s in sentences:\n",
    "    sentence_emb = []\n",
    "    for w in s:\n",
    "        sentence_emb.append(wordvectors[w])\n",
    "    sentence_embeddings.append(sentence_emb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentence_embeddings, np.array(tags_encoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pad the sentences with zero to make all sentences of equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    "train_sentences_X = pad_sequences(X_train, maxlen=MAX_LENGTH, padding='post')\n",
    "test_sentences_X = pad_sequences(X_test, maxlen=MAX_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 127)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 127, 128)          2197504   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 512)               788480    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 1539      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,987,523\n",
      "Trainable params: 2,987,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# architecture\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout, InputLayer, Bidirectional, TimeDistributed, Activation, Embedding\n",
    "from keras.optimizers import Adam\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH,)))\n",
    "model.add(Embedding(len(wordvectors)+1, 128))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=False)))\n",
    "model.add(Dense(len(unique_tags)))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(0.001),\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As the data set is highly imbalanced we will give our class weight while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y_integers = np.argmax(tags_encoding, axis=1)\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
    "d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "17981/17981 [==============================] - 120s 7ms/step - loss: 0.1198 - acc: 0.9278\n",
      "Epoch 2/5\n",
      "17981/17981 [==============================] - 116s 6ms/step - loss: 0.1052 - acc: 0.9372\n",
      "Epoch 3/5\n",
      "17981/17981 [==============================] - 117s 6ms/step - loss: 0.0931 - acc: 0.9432\n",
      "Epoch 4/5\n",
      "17981/17981 [==============================] - 114s 6ms/step - loss: 0.0839 - acc: 0.9497\n",
      "Epoch 5/5\n",
      "17981/17981 [==============================] - 114s 6ms/step - loss: 0.0811 - acc: 0.9510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b0b7bc550>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sentences_X, y_train, batch_size=100, epochs=5, class_weight = d_class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('models/text_classification_model.h5')\n",
    "model = load_model('models/text_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5994/5994 [==============================] - 12s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_sentences_X, y_test, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.59225850595328\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", score[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained for 3 classes.\n",
    "The tags are one hot encoded.\n",
    "For embedding of sentences, keras embedding layer is used. The embedding size is kept 128.\n",
    "The model architecture is as follows: 1. Embedding Layer(to generate word embeddings) 2. Next layer Bidirectional LSTM. 3. Feed forward layer with number of neurons = number of tags 4. softmax activation to get probabilities\n",
    "\n",
    "Since the dataset is highly unbalanced class weights are supplied while training. \n",
    "An accuracy of 75% is achieved on the test data. \n",
    "The accuracy of the training set is high in comparison to the accuracy on test data.This is due to overfitting. \n",
    "To improve the accuracy further the model can be trained on more data. This will solve the problem of high variance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
